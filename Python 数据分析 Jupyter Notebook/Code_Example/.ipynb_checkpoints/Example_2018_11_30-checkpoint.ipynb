{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 list 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法一去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "detail = pd.read_csv(\"../data/detail.csv\", index_col = 0, encoding = \"gbk\")\n",
    "\n",
    "# 方法一\n",
    "# 定义去重函数\n",
    "\n",
    "def delRep(list1):\n",
    "    list2 = []\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2\n",
    "\n",
    "# 去重\n",
    "\n",
    "dishes = list(detail[\"dishes_name\"]) # 将 dishes_name 从数据框中提取出来\n",
    "print(\"去重前菜品总数为：\", len(dishes))\n",
    "dish = delRep(dishes) # 使用自定义的去重函数去重\n",
    "print(\"方法一去重后菜品总数为：\", len(dish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 set 的特性去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法二去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "# 方法二\n",
    "\n",
    "print(\"去重前菜品总数为：\", len(dishes))\n",
    "dish_set = set(dishes) # 利用 set 的特性去重\n",
    "print(\"方法二去重后菜品总数为：\", len(dish_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 drop_duplicates 方法对菜品名称去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates 方法去重之后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "# 对 dishes_name 去重\n",
    "\n",
    "dishes_name = detail[\"dishes_name\"].drop_duplicates()\n",
    "print(\"drop_duplicates 方法去重之后菜品总数为：\", len(dishes_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 drop_duplicates 方法对多列去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前订单详情表的形状为： (10037, 18)\n",
      "依照订单编号，会员编号去重之后订单详情表大小为： (942, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"去重之前订单详情表的形状为：\", detail.shape)\n",
    "shapeDet = detail.drop_duplicates(subset = [ \"order_id\",\"emp_id\" ]).shape\n",
    "print(\"依照订单编号，会员编号去重之后订单详情表大小为：\", shapeDet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求出 counts 和 amounts 两列数据的 kendall 法相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销量和售价的 kendall 法相似度矩阵为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.229968\n",
      "amounts -0.229968  1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求出销量和售价的相似度\n",
    "\n",
    "corrDet = detail[[ \"counts\",\"amounts\" ]].corr(method = \"kendall\")\n",
    "print(\"销量和售价的 kendall 法相似度矩阵为：\\n\", corrDet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求出 dishes_name、counts 和 amounts 这 3 个特征的 pearson 法相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品名称、销量和售价的 pearson 法相似度矩阵为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.159264\n",
      "amounts -0.159264  1.000000\n"
     ]
    }
   ],
   "source": [
    "corrDet1 = detail[[ \"dishes_name\",\"counts\",\"amounts\" ]].corr(method = \"pearson\")\n",
    "print(\"菜品名称、销量和售价的 pearson 法相似度矩阵为：\\n\", corrDet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 DataFrame.equals 方法去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail 的特征相等矩阵的前 5 行 5 列为：\n",
      "                    order_id  dishes_id  logicprn_name  parent_class_name  \\\n",
      "order_id               True      False          False              False   \n",
      "dishes_id             False       True          False              False   \n",
      "logicprn_name         False      False           True               True   \n",
      "parent_class_name     False      False           True               True   \n",
      "dishes_name           False      False          False              False   \n",
      "\n",
      "                   dishes_name  \n",
      "order_id                 False  \n",
      "dishes_id                False  \n",
      "logicprn_name            False  \n",
      "parent_class_name        False  \n",
      "dishes_name               True  \n"
     ]
    }
   ],
   "source": [
    "# 定义求取特征是否完全相同的矩阵的函数\n",
    "\n",
    "def FeatureEquals(df):\n",
    "    dfEquals = pd.DataFrame([], columns = df.columns, index = df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j] = df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "\n",
    "# 应用上述函数\n",
    "\n",
    "detEquals = FeatureEquals(detail)\n",
    "print(\"detail 的特征相等矩阵的前 5 行 5 列为：\\n\", detEquals.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过遍历的方式进行数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为： ['parent_class_name', 'cost', 'discount_amt', 'discount_reason', 'kick_back', 'add_info', 'bar_code', 'add_inprice']\n",
      "删除多余列后 detail 的特征数目为： 10\n"
     ]
    }
   ],
   "source": [
    "# 遍历所有数据\n",
    "\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k + 1, lenDet):\n",
    "        if detEquals.iloc[k,l]&(detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "            \n",
    "# 进行去重操作\n",
    "\n",
    "print(\"需要删除的列为：\", dupCol)\n",
    "detail.drop(dupCol, axis = 1, inplace = True)\n",
    "print(\"删除多余列后 detail 的特征数目为：\", detail.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isnull 和 notnull 用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail 每个特征缺失的数目为：\n",
      " order_id                0\n",
      "dishes_id               0\n",
      "logicprn_name       10037\n",
      "dishes_name             0\n",
      "itemis_add              0\n",
      "counts                  0\n",
      "amounts                 0\n",
      "place_order_time        0\n",
      "picture_file            0\n",
      "emp_id                  0\n",
      "dtype: int64\n",
      "detail 每个特征非缺失的数目为：\n",
      " order_id            10037\n",
      "dishes_id           10037\n",
      "logicprn_name           0\n",
      "dishes_name         10037\n",
      "itemis_add          10037\n",
      "counts              10037\n",
      "amounts             10037\n",
      "place_order_time    10037\n",
      "picture_file        10037\n",
      "emp_id              10037\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"detail 每个特征缺失的数目为：\\n\", detail.isnull().sum())\n",
    "print(\"detail 每个特征非缺失的数目为：\\n\", detail.notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropna 主要参数及其说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna 函数：\n",
    "\n",
    "# pandas.DataFrame.dropna(self, axis = 0, how = \"any\", thresh = None, subset = None, inplace = False)\n",
    "\n",
    "# axis                接收 0 或 1。表示轴向，0 为删除观测记录（行），1 为删除特征（列）。默认为 0\n",
    "\n",
    "# how                 接收待定 string。表示删除的形式。any 表示只要有缺失值存在就执行删除操作；all 表示\n",
    "#                     当且仅当全部为缺失值时才执行删除操作。默认为 any\n",
    "\n",
    "# subset              接收 array。表示进行去重的列/行。默认为 None，表示所有列/行\n",
    "\n",
    "# inplace             接收 boolean。表示是否在原表上进行操作。默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 dropna 方法删除缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除缺失的列前 detail 的形状为： (10037, 10)\n",
      "去除缺失的列后 detail 的形状为： (10037, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"去除缺失的列前 detail 的形状为：\", detail.shape)\n",
    "print(\"去除缺失的列后 detail 的形状为：\", detail.dropna(axis = 1, how = \"any\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fillna 主要参数及其说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna 函数：\n",
    "\n",
    "# pandas.DataFrame.fillna(value = None, method = None, axis = None, inplace = False, limit = None)\n",
    "\n",
    "# value         接收待定 string\n",
    "#               backfill 或 bfill 表示使用下一个非缺失值来填补缺失值\n",
    "#               pad 或 ffill 表示使用上一个非缺失值来填补缺失值。默认为 None\n",
    "\n",
    "# axis          接收 0 或 1。表示轴向。默认为 1\n",
    "\n",
    "# inplace       接收 boolean。表示是否在原表上进行操作。默认为 False\n",
    "\n",
    "# limit         接收 int。表示填补缺失值个数上限，超过则不进行填补。默认为 None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 fillna 方法替换缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail 每个特征缺失的数目为：\n",
      " order_id            0\n",
      "dishes_id           0\n",
      "logicprn_name       0\n",
      "dishes_name         0\n",
      "itemis_add          0\n",
      "counts              0\n",
      "amounts             0\n",
      "place_order_time    0\n",
      "picture_file        0\n",
      "emp_id              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "detail = detail.fillna(-99)\n",
    "print(\"detail 每个特征缺失的数目为：\\n\", detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy interpolate 模块插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当 x 为 6、7 时，使用线性插值 y1 为： [ 76. 102.]\n",
      "当 x 为 6、7 时，使用线性插值 y2 为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "# 线性插值\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "x = np.array([ 1,2,3,4,5,8,9,10 ]) # 创建自变量 x\n",
    "y1 = np.array([ 2,8,18,32,50,128,162,200 ]) # 创建因变量 y1\n",
    "y2 = np.array([ 3,5,7,9,11,17,19,21 ]) #  创建因变量 y2\n",
    "LinearInsValue1 = interp1d(x, y1, kind = \"linear\") # 线性插值拟合 x、y1\n",
    "LinearInsValue2 = interp1d(x, y2, kind = \"linear\") # 线性插值拟合 x、y2\n",
    "print(\"当 x 为 6、7 时，使用线性插值 y1 为：\", LinearInsValue1([ 6,7 ]))\n",
    "print(\"当 x 为 6、7 时，使用线性插值 y2 为：\", LinearInsValue2([ 6,7 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当 x 为 6，7 时，使用拉格朗日插值 y1 为： [72. 98.]\n",
      "当 x 为 6，7 时，使用拉格朗日插值 y2 为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "# 拉格朗日插值\n",
    "\n",
    "from scipy.interpolate import lagrange\n",
    "\n",
    "LargeInsValue1 = lagrange(x, y1) # 拉格朗日插值拟合 x、y1\n",
    "LargeInsValue2 = lagrange(x, y2) # 拉格朗日插值拟合 x、y2\n",
    "print(\"当 x 为 6，7 时，使用拉格朗日插值 y1 为：\", LargeInsValue1([ 6,7 ]))\n",
    "print(\"当 x 为 6，7 时，使用拉格朗日插值 y2 为：\", LargeInsValue2([ 6,7 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当 x 为 6，7 时，使用样条插值 y1 为： [72. 98.]\n",
      "当 x 为 6，7 时，使用样条插值 y2 为： [13. 15.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `spline` is deprecated!\n",
      "spline is deprecated in scipy 0.19.0, use Bspline class instead.\n",
      "  import sys\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: `spline` is deprecated!\n",
      "spline is deprecated in scipy 0.19.0, use Bspline class instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# 样条插值\n",
    "\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "# 样条插值拟合 x、y1\n",
    "\n",
    "SplineInsValue1 = spline(x, y1, xnew = np.array([ 6,7 ]))\n",
    "\n",
    "# 样条插值拟合 x、y2\n",
    "\n",
    "SplineInsValue2 = spline(x, y2, xnew = np.array([ 6,7 ]))\n",
    "print(\"当 x 为 6，7 时，使用样条插值 y1 为：\", SplineInsValue1)\n",
    "print(\"当 x 为 6，7 时，使用样条插值 y2 为：\", SplineInsValue2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 3σ 原则识别异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 3σ 原则判断异常值个数为： 209\n",
      "异常值的最大值为： 10\n",
      "异常值的最小值为： 3\n"
     ]
    }
   ],
   "source": [
    "# 定义 3σ 原则来识别异常值函数\n",
    "\n",
    "def outRange(Ser1):\n",
    "    boolInd = (Ser1.mean() - 3 * Ser1.std() > Ser1)|(Ser1.mean() + 3 * Ser1.var() < Ser1)\n",
    "    index = np.arange(Ser1.shape[0])[boolInd]\n",
    "    outrange = Ser1.iloc[index]\n",
    "    return outrange\n",
    "outlier = outRange(detail[\"counts\"])\n",
    "print(\"使用 3σ 原则判断异常值个数为：\", outlier.shape[0])\n",
    "print(\"异常值的最大值为：\", outlier.max())\n",
    "print(\"异常值的最小值为：\", outlier.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 菜品售价根据箱线图识别异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量数据异常值个数为： 516\n",
      "销售量数据异常的最大值为： 10\n",
      "销售量数据异常的最小值为： 2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "p = plt.boxplot(detail[\"counts\"].values, notch = True) # 画出箱线图\n",
    "outlier1 = p[\"fliers\"][0].get_ydata() # fliers 为异常值的标签\n",
    "plt.savefig(\"../tmp/菜品异常数据识别.png\")\n",
    "plt.show()\n",
    "print(\"销售量数据异常值个数为：\", len(outlier1))\n",
    "print(\"销售量数据异常的最大值为：\", max(outlier1))\n",
    "print(\"销售量数据异常的最小值为：\", min(outlier1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表的样本去重与特征去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行去重操作前订单详情表的形状为： (10037, 18)\n",
      "进行去重操作后订单详情表的形状为： (10037, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "detail = pd.read_csv(\"../data/detail.csv\", index_col = 0, encoding = \"gbk\")\n",
    "print(\"进行去重操作前订单详情表的形状为：\", detail.shape)\n",
    "\n",
    "# 样本去重\n",
    "\n",
    "detail.drop_duplicates(inplace = True)\n",
    "\n",
    "# 特征去重\n",
    "\n",
    "def FeatureEquals(df):\n",
    "    # 定义求取特征是否完全相同的矩阵的函数\n",
    "    dfEquals = pd.DataFrame([],columns = df.columns, index = df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j] = df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "detEquals = FeatureEquals(detail) # 应用上述函数\n",
    "\n",
    "# 遍历所有数据\n",
    "\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k + 1, lenDet):\n",
    "        if detEquals.iloc[k,l]&(detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "\n",
    "# 删除重复列\n",
    "\n",
    "detail.drop(dupCol, axis = 1, inplace = True)\n",
    "print(\"进行去重操作后订单详情表的形状为：\", detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表的缺失值检测与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail 每个特征缺失的率为：\n",
      " order_id              0.0%\n",
      "dishes_id             0.0%\n",
      "logicprn_name       100.0%\n",
      "dishes_name           0.0%\n",
      "itemis_add            0.0%\n",
      "counts                0.0%\n",
      "amounts               0.0%\n",
      "place_order_time      0.0%\n",
      "picture_file          0.0%\n",
      "emp_id                0.0%\n",
      "dtype: object\n",
      "经过缺失值处理后订单详情表各特征缺失值的数目为：\n",
      " order_id            0\n",
      "dishes_id           0\n",
      "dishes_name         0\n",
      "itemis_add          0\n",
      "counts              0\n",
      "amounts             0\n",
      "place_order_time    0\n",
      "picture_file        0\n",
      "emp_id              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 统计各个特征的缺失率\n",
    "\n",
    "naRate = (detail.isnull().sum() / detail.shape[0] * 100).astype(\"str\") + \"%\"\n",
    "print(\"detail 每个特征缺失的率为：\\n\", naRate)\n",
    "\n",
    "# 删除全部数据均为缺失的列\n",
    "\n",
    "detail.dropna(axis = 1, how = \"all\", inplace = True)\n",
    "print(\"经过缺失值处理后订单详情表各特征缺失值的数目为：\\n\", detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表异常值检测与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量最小值为： 1.0\n",
      "销售量最大值为： 1.0\n",
      "售价最小值为： 1.0\n",
      "售价最大值为： 99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# 定义异常值识别与处理函数\n",
    "\n",
    "def outRange(Ser1):\n",
    "    QL = Ser1.quantile(0.25)\n",
    "    QU = Ser1.quantile(0.75)\n",
    "    IQR = QU - QL\n",
    "    Ser1.loc[Ser1 > (QU + 1.5 * IQR)] = QU\n",
    "    Ser1.loc[Ser1 < (QL - 1.5 * IQR)] = QL\n",
    "    return Ser1\n",
    "\n",
    "# 处理销售量和售价的异常值\n",
    "\n",
    "detail[\"counts\"] = outRange(detail[\"counts\"])\n",
    "detail[\"amounts\"] = outRange(detail[\"amounts\"])\n",
    "\n",
    "# 查看处理后的销售量，售价的最小值、最大值\n",
    "\n",
    "print(\"销售量最小值为：\", detail[\"counts\"].min())\n",
    "print(\"销售量最大值为：\", detail[\"counts\"].max())\n",
    "print(\"售价最小值为：\", detail[\"amounts\"].min())\n",
    "print(\"售价最大值为：\", detail[\"amounts\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离差标准化示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离差标准化之前销量和售价数据为：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956            1       49\n",
      "2958            1       48\n",
      "2961            1       30\n",
      "2966            1       25\n",
      "2968            1       13\n",
      "离差标准化之后销量和售价数据为：\n",
      "            counts   amounts\n",
      "detail_id                  \n",
      "2956          0.0  0.271186\n",
      "2958          0.0  0.265537\n",
      "2961          0.0  0.163842\n",
      "2966          0.0  0.135593\n",
      "2968          0.0  0.067797\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "detail = pd.read_csv(\"../data/detail.csv\", index_col = 0, encoding = \"gbk\")\n",
    "\n",
    "# 自定义离差标准化函数\n",
    "\n",
    "def MinMaxScale(data):\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    return data\n",
    "\n",
    "# 对菜品订单表售价和销量做离差标准化\n",
    "\n",
    "data1 = MinMaxScale(detail[\"counts\"])\n",
    "data2 = MinMaxScale(detail[\"amounts\"])\n",
    "data3 = pd.concat([ data1,data2 ], axis = 1)\n",
    "print(\"离差标准化之前销量和售价数据为：\\n\", detail[[ \"counts\",\"amounts\" ]].head())\n",
    "print(\"离差标准化之后销量和售价数据为：\\n\", data3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标准差标准化示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准差标准化之前销量和售价数据为：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956            1       49\n",
      "2958            1       48\n",
      "2961            1       30\n",
      "2966            1       25\n",
      "2968            1       13\n",
      "标准差标准化之后销量和售价数据为：\n",
      "              counts   amounts\n",
      "detail_id                    \n",
      "2956      -0.177571  0.116671\n",
      "2958      -0.177571  0.088751\n",
      "2961      -0.177571 -0.413826\n",
      "2966      -0.177571 -0.553431\n",
      "2968      -0.177571 -0.888482\n"
     ]
    }
   ],
   "source": [
    "# 自定义标准差标准化函数\n",
    "\n",
    "def StandardScaler(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data\n",
    "\n",
    "# 菜品订单表售价和销量做标准化\n",
    "\n",
    "data4 = StandardScaler(detail[\"counts\"])\n",
    "data5 = StandardScaler(detail[\"amounts\"])\n",
    "data6 = pd.concat([ data4,data5 ], axis = 1)\n",
    "print(\"标准差标准化之前销量和售价数据为：\\n\", detail[[ \"counts\",\"amounts\" ]].head())\n",
    "print(\"标准差标准化之后销量和售价数据为：\\n\", data6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小数定标标准化示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小数定标标准化之前的销量和售价数据：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956            1       49\n",
      "2958            1       48\n",
      "2961            1       30\n",
      "2966            1       25\n",
      "2968            1       13\n",
      "小数定标标准化之后的销量和售价数据：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956          0.1    0.049\n",
      "2958          0.1    0.048\n",
      "2961          0.1    0.030\n",
      "2966          0.1    0.025\n",
      "2968          0.1    0.013\n"
     ]
    }
   ],
   "source": [
    "# 自定义小数定标标准化函数\n",
    "\n",
    "def DecimalScaler(data):\n",
    "    data = data / 10 ** np.ceil(np.log10(data.abs().max()))\n",
    "    return data\n",
    "\n",
    "# 对菜品订单表售价和销量做标准化\n",
    "\n",
    "data7 = DecimalScaler(detail[\"counts\"])\n",
    "data8 = DecimalScaler(detail[\"amounts\"])\n",
    "data9 = pd.concat([ data7,data8 ], axis = 1)\n",
    "print(\"小数定标标准化之前的销量和售价数据：\\n\", detail[[ \"counts\",\"amounts\" ]].head())\n",
    "print(\"小数定标标准化之后的销量和售价数据：\\n\", data9.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对订单详情表中的数值型数据做标准差标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准差标准化之后售价和销量数据为：\n",
      "              counts   amounts\n",
      "detail_id                    \n",
      "2956      -0.177571  0.116671\n",
      "2958      -0.177571  0.088751\n",
      "2961      -0.177571 -0.413826\n",
      "2966      -0.177571 -0.553431\n",
      "2968      -0.177571 -0.888482\n",
      "1899      -0.177571  1.205587\n",
      "1902      -0.177571  0.284197\n",
      "1906      -0.177571  1.205587\n",
      "1907      -0.177571  0.088751\n",
      "1908      -0.177571 -0.357984\n"
     ]
    }
   ],
   "source": [
    "# 自定义标准差标准化函数\n",
    "\n",
    "def StandardScaler(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data\n",
    "\n",
    "# 对菜品订单表售价和销量做标准化\n",
    "\n",
    "data4 = StandardScaler(detail[\"counts\"])\n",
    "data5 = StandardScaler(detail[\"amounts\"])\n",
    "data6 = pd.concat([ data4,data5 ], axis = 1)\n",
    "print(\"标准差标准化之后售价和销量数据为：\\n\", data6.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_dummies 函数的参数及说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies 函数：\n",
    "\n",
    "# pandas.get_dummies(data, prefix = None, prefix_sep = \"_\", dummy_na = False, columns = None, sparse = False, drop_first = False)\n",
    "\n",
    "# data             接收 array、DataFrame 或者 Series。表示需要哑变量处理的数据。无默认\n",
    "\n",
    "# prefix           接收 string、string 的列表或者 string 的 dict。表示哑变量化后列名的前缀。默认为 None\n",
    "\n",
    "# prefix_sep       接收 string。表示前缀的连接符。默认为 \"_\"\n",
    "\n",
    "# dummy_na         接收 boolean。表示是否为 NaN 值添加一列。默认为 False\n",
    "\n",
    "# columns          接收类似 list 的数据。表示 DataFrame 中需要编码的列名。默认为 None，表示对所有 object 和 category 类型进行编码\n",
    "\n",
    "# sparse           接收 boolean。表示虚拟列是否是稀疏的。默认为 False\n",
    "\n",
    "# drop_first       接收 boolean。表示是否通过从 k 个分类级别中删除第一级来获得 k-1 个分类级别。默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 哑变量处理示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哑变量处理前的数据为：\n",
      " 0     蒜蓉生蚝\n",
      "1    蒙古烤羊腿\n",
      "2     大蒜苋菜\n",
      "3    芝麻烤紫菜\n",
      "4      蒜香包\n",
      "5      白斩鸡\n",
      "Name: dishes_name, dtype: object\n",
      "哑变量处理后的数据为：\n",
      "    大蒜苋菜  白斩鸡  芝麻烤紫菜  蒙古烤羊腿  蒜蓉生蚝  蒜香包\n",
      "0     0    0      0      0     1    0\n",
      "1     0    0      0      1     0    0\n",
      "2     1    0      0      0     0    0\n",
      "3     0    0      1      0     0    0\n",
      "4     0    0      0      0     0    1\n",
      "5     0    1      0      0     0    0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "detail = pd.read_csv(\"../data/detail.csv\", encoding = \"gbk\")\n",
    "data = detail.loc[0:5,\"dishes_name\"] # 抽取部分数据做演示\n",
    "print(\"哑变量处理前的数据为：\\n\", data)\n",
    "print(\"哑变量处理后的数据为：\\n\",pd.get_dummies(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
