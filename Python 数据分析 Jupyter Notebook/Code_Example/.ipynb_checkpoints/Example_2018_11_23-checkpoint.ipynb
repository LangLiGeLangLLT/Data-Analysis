{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge 函数的参数及其说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 函数：\n",
    "\n",
    "# pandas.merge(left, right, how = \"inner\", on = None, left_on = None, right_on = None, left_index = False, right_index = False,\n",
    "#              sort = False, suffixes = (\"_x\", \"_y\"), copy = True, indicator = False)\n",
    "\n",
    "# left               接收 DataFrame 或 Series。表示要添加的新数据 1。无默认\n",
    "\n",
    "# right              接收 DataFrame 或 Series。表示要添加的新数据 2。无默认\n",
    "\n",
    "# how                接收 inner、outer、left、right。表示数据的连接方式。默认为 inner\n",
    "\n",
    "# on                 接收 string 或 sequence。表示两个数据合并的主键（必须一致）。默认为 None\n",
    "\n",
    "# left_on            接收 string 或 sequence。表示 left 参数接收数据用于合并的主键。默认为 None\n",
    "\n",
    "# right_on           接收 string 或 sequence。表示 right 参数接收数据用于合并的主键。默认为 None\n",
    "\n",
    "# left_index         接收 boolean。表示是否将 left 参数接收数据的 index 作为连接主键。默认为 False\n",
    "\n",
    "# right_index        接收 boolean。表示是否将 right 参数接收数据的 index 作为连接主键。默认为 False\n",
    "\n",
    "# sort               接收 boolean。表示是否根据连接键对合并后的数据进行排序。默认为 False\n",
    "\n",
    "# suffixes           表示用于追加到 left 和 right 参数接收数据列名相同时的后缀。默认为 (\"_x\", \"_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 merge 函数合并数据表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail1 订单详情表的原始形状为： (2779, 19)\n",
      "order 订单信息表的原始形状为： (945, 21)\n",
      "订单详情表和订单信息表主键合并后的形状为： (2779, 40)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/testdb?charset=utf8\")\n",
    "detail1 = pd.read_sql(\"meal_order_detail1\", conn)\n",
    "order = pd.read_csv(\"../data/meal_order_info.csv\", sep = \",\", encoding = \"gb18030\") # 读取订单信息表\n",
    "\n",
    "# 将 info_id 转换为字符串格式，为合并做准备\n",
    "\n",
    "order[\"info_id\"] = order[\"info_id\"].astype(\"str\")\n",
    "# detail1[\"order_id\"] = detail1[\"order_id\"].astype(\"int64\")\n",
    "\n",
    "# 订单详情表和订单信息表都有订单编号\n",
    "# 在订单详情表中为 order_id，在订单信息表中为 info_id\n",
    "\n",
    "order_detail = pd.merge(detail1, order, left_on = \"order_id\", right_on = \"info_id\")\n",
    "print(\"detail1 订单详情表的原始形状为：\", detail1.shape)\n",
    "print(\"order 订单信息表的原始形状为：\", order.shape)\n",
    "print(\"订单详情表和订单信息表主键合并后的形状为：\", order_detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join 方法的参数及其说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 函数：\n",
    "\n",
    "# pandas.DataFrame.join(self, other, on = None, how = \"left\", lsuffix = \"\", rsuffix = \"\", sort = False)\n",
    "\n",
    "# other               接收 DataFrame、Series 或者包含了多个 DataFrame 的 list。表示参与连接的其他 DataFrame。无默认\n",
    "\n",
    "# on                  接收列名或者包含列名的 list 或 tuple。表示用于连接的列名。默认为 None\n",
    "\n",
    "# how                 接收待定 string。inner 代表内连接；outer 代表外连接；left 和 right 分别代表左连接和右连接。默认为 inner\n",
    "\n",
    "# lsuffix             接收 string。表示用于追加到左侧重叠列名的尾缀。无默认\n",
    "\n",
    "# rsuffix             接收 string。表示用于追加到右侧重叠列名的尾缀。无默认\n",
    "\n",
    "# sort                接收 boolean。根据连接键对合并后的数据进行排序，默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 join 方法实现主键合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表和订单信息表 join 合并后的形状为： (2779, 40)\n"
     ]
    }
   ],
   "source": [
    "order.rename({ \"info_id\":\"order_id\" }, inplace = True)\n",
    "detail1[\"order_id\"] = detail1[\"order_id\"].astype(\"int64\")\n",
    "order_detail1 = detail1.join(order, on = \"order_id\", rsuffix = \"1\")\n",
    "print(\"订单详情表和订单信息表 join 合并后的形状为：\", order_detail1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine_first 方法常用参数及其说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_first 函数：\n",
    "\n",
    "# pandas.DataFrame.combine_first(other)\n",
    "\n",
    "# other              接收 DataFrame。表示参与重叠合并的另一个 DataFrame。无默认"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重叠合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过重叠合并后的数据为：\n",
      "    ID System cpu\n",
      "0   1  win10  i7\n",
      "1   2  win10  i5\n",
      "2   3   win7  i3\n",
      "3   4  win10  i7\n",
      "4   5   win8  i7\n",
      "5   6   win7  i5\n",
      "6   7   win7  i5\n",
      "7   8   win7  i5\n",
      "8   9   win8  i3\n"
     ]
    }
   ],
   "source": [
    "# 建立两个字典，除了 ID 外，别的特征互补\n",
    "\n",
    "dict1 = { \"ID\":[ 1,2,3,4,5,6,7,8,9 ],\n",
    "          \"System\":[ \"win10\",\"win10\",np.nan,\"win10\",np.nan,np.nan,\"win7\",\"win7\",\"win8\" ],\n",
    "          \"cpu\":[ \"i7\",\"i5\",np.nan,\"i7\",np.nan,np.nan,\"i5\",\"i5\",\"i3\" ] }\n",
    "dict2 = { \"ID\":[ 1,2,3,4,5,6,7,8,9 ],\n",
    "          \"System\":[ np.nan,np.nan,\"win7\",np.nan,\"win8\",\"win7\",np.nan,np.nan,np.nan ],\n",
    "          \"cpu\":[ np.nan,np.nan,\"i3\",np.nan,\"i7\",\"i5\",np.nan,np.nan,np.nan ] }\n",
    "\n",
    "# 转换两个字典为 DataFrame\n",
    "\n",
    "df5 = pd.DataFrame(dict1)\n",
    "df6 = pd.DataFrame(dict2)\n",
    "print(\"经过重叠合并后的数据为：\\n\", df5.combine_first(df6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将多张菜品订单详情表纵向合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 张订单详情表合并后的形状为： (10037, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 创建数据库连接\n",
    "\n",
    "conn = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/testdb?charset=utf8\")\n",
    "\n",
    "# 读取数据\n",
    "\n",
    "detail1 = pd.read_sql(\"meal_order_detail1\", conn)\n",
    "detail2 = pd.read_sql(\"meal_order_detail2\", conn)\n",
    "detail3 = pd.read_sql(\"meal_order_detail3\", conn)\n",
    "\n",
    "# 纵向堆叠 3 张表\n",
    "\n",
    "detail = detail1.append(detail2)\n",
    "detail = detail.append(detail3)\n",
    "print(\"3 张订单详情表合并后的形状为：\", detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表、订单信息表、客户信息表主键合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 张表数据主键合并后的大小为： (10037, 76)\n"
     ]
    }
   ],
   "source": [
    "order = pd.read_csv(\"../data/meal_order_info.csv\", sep = \",\", encoding = \"gb18030\") # 读取订单信息表\n",
    "user = pd.read_excel(\"../data/users_info.xlsx\") # 读取客户信息表\n",
    "\n",
    "# 数据类型转换，存储部分数据\n",
    "\n",
    "order[\"info_id\"] = order[\"info_id\"].astype(\"str\")\n",
    "order[\"emp_id\"] = order[\"emp_id\"].astype(\"str\")\n",
    "user[\"USER_ID\"] = user[\"USER_ID\"].astype(\"str\")\n",
    "data = pd.merge(detail, order, left_on = [ \"order_id\",\"emp_id\" ], right_on = [ \"info_id\",\"emp_id\" ])\n",
    "data = pd.merge(data, user, left_on = \"emp_id\", right_on = \"USER_ID\", how = \"inner\")\n",
    "print(\"3 张表数据主键合并后的大小为：\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 list 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法一去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "detail = pd.read_csv(\"../data/detail.csv\", index_col = 0,encoding = \"gbk\")\n",
    "\n",
    "# 方法一\n",
    "# 定义去重函数\n",
    "\n",
    "def delRep(list1):\n",
    "    list2 = []\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2\n",
    "\n",
    "# 去重\n",
    "\n",
    "dishes = list(detail[\"dishes_name\"]) # 将 dishes_name 从数据框中提取出来\n",
    "print(\"去重前菜品总数为：\",len(dishes))\n",
    "dish = delRep(dishes) # 使用自定义的去重函数去重\n",
    "print(\"方法一去重后菜品总数为：\", len(dish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 set 的特性去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法二去重后的菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "# 方法二\n",
    "\n",
    "print(\"去重前菜品总数为：\", len(dishes))\n",
    "dish_set = set(dishes) # 利用 set 的特性去重\n",
    "print(\"方法二去重后的菜品总数为：\", len(dish_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop_duplicates 方法的常用参数及其说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_duplicates 函数：\n",
    "\n",
    "# pandas.DataFrame(Series).drop_duplicates(self, subset = None, keep = \"first\", inplace = False)\n",
    "\n",
    "# subset               接收 string 或 sequence。表示进行去重的列。默认为 None，表示全部列\n",
    "\n",
    "# keep                 接收待定 string。表示重复时保留第几个数据\n",
    "#                      first：保留第一个\n",
    "#                      last：保留最后一个\n",
    "#                      false：只要有重复都不保留\n",
    "#                      默认为first\n",
    "\n",
    "# inplace              接收 boolean。表示是否在原表上进行操作。默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 drop_duplicates 方法对菜品名称去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates 方法去重之后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "# 对 dishes_name 去重\n",
    "\n",
    "dishes_name = detail[\"dishes_name\"].drop_duplicates()\n",
    "print(\"drop_duplicates 方法去重之后菜品总数为：\", len(dishes_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 drop_duplicates 方法对多列去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前订单详情表的形状为： (10037, 18)\n",
      "依照订单编号，会员编号去重之后订单详情表大小为： (942, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"去重之前订单详情表的形状为：\", detail.shape)\n",
    "shapeDet = detail.drop_duplicates(subset = [ \"order_id\",\"emp_id\" ]).shape\n",
    "print(\"依照订单编号，会员编号去重之后订单详情表大小为：\", shapeDet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求出 counts 和 amounts 两列数据的 kendall 发相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销量和售价的 kendall 法相似度矩阵为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.253092\n",
      "amounts -0.253092  1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求取销量和售价的相似度\n",
    "\n",
    "corrDet = detail1[[ \"counts\",\"amounts\" ]].corr(method = \"kendall\")\n",
    "print(\"销量和售价的 kendall 法相似度矩阵为：\\n\", corrDet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求出 dishes_name、counts 和 amounts 这 3 个特征的 pearson 法相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品名称、销量和售价的 pearson 法相似度矩阵为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.159264\n",
      "amounts -0.159264  1.000000\n"
     ]
    }
   ],
   "source": [
    "corrDet1 = detail[[ \"dishes_name\",\"counts\",\"amounts\" ]].corr(method = \"pearson\")\n",
    "print(\"菜品名称、销量和售价的 pearson 法相似度矩阵为：\\n\", corrDet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 DataFrame.equals 方法去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail 的特征相等矩阵的前 5 行 5 列为：\n",
      "                    order_id  dishes_id  logicprn_name  parent_class_name  \\\n",
      "order_id               True      False          False              False   \n",
      "dishes_id             False       True          False              False   \n",
      "logicprn_name         False      False           True               True   \n",
      "parent_class_name     False      False           True               True   \n",
      "dishes_name           False      False          False              False   \n",
      "\n",
      "                   dishes_name  \n",
      "order_id                 False  \n",
      "dishes_id                False  \n",
      "logicprn_name            False  \n",
      "parent_class_name        False  \n",
      "dishes_name               True  \n"
     ]
    }
   ],
   "source": [
    "# 定义求取特征是否完全相同的矩阵的函数\n",
    "\n",
    "def FeatureEquals(df):\n",
    "    dfEquals = pd.DataFrame([], columns = df.columns, index = df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j] = df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "\n",
    "# 应用上述函数\n",
    "\n",
    "detEquals = FeatureEquals(detail)\n",
    "print(\"detail 的特征相等矩阵的前 5 行 5 列为：\\n\", detEquals.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过遍历的方式进行数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为： ['parent_class_name', 'cost', 'discount_amt', 'discount_reason', 'kick_back', 'add_info', 'bar_code', 'add_inprice']\n",
      "删除多余列后 detail 的特征数目为： 10\n"
     ]
    }
   ],
   "source": [
    "# 遍历所有数据\n",
    "\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k + 1, lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "\n",
    "# 进行去重操作\n",
    "\n",
    "print(\"需要删除的列为：\", dupCol)\n",
    "detail.drop(dupCol, axis = 1, inplace = True)\n",
    "print(\"删除多余列后 detail 的特征数目为：\", detail.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
