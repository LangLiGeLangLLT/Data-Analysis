{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 pivot_table 函数创建透视表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pivot_table 函数：\n",
    "\n",
    "pandas.pivot_table(data, values = None, index = None, columns = None, aggfunc = \"mean\", fill_value = None, margins = False, dropna = True,\n",
    "margins_name = \"All\")\n",
    "\n",
    "data               接受 DataFrame。表示创建表的数据。无默认\n",
    "\n",
    "values             接受 string。用于指定要聚合的数据字段名，默认使用全部数据。默认为 None\n",
    "\n",
    "index              接受 string 或 list。表示行分组键。默认为 None\n",
    "\n",
    "columns            接受 string 或 list。表示列分组键。默认为 None\n",
    "\n",
    "aggfunc            接受 functions。表示聚合函数。默认为 mean\n",
    "\n",
    "margins            接受 boolean。表示汇（Total）功能的开关，设置为 True 后，结果集中会出现名为“ALL”的行和列。默认为 True\n",
    "\n",
    "dropna             接受 boolean。表示是否删掉全为 NaN 的列。默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用订单号作为透视表索引制作透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以 order_id 作为分组键创建的订单透视表为：\n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002       32.000  1.0000\n",
      "1003       30.125  1.2500\n",
      "1004       43.875  1.0625\n",
      "1008       63.000  1.0000\n",
      "1011       57.700  1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/testdb?charset=utf8\")\n",
    "detail = pd.read_sql_table(\"meal_order_detail1\", con = engine)\n",
    "detailPivot = pd.pivot_table(detail[[ \"order_id\",\"counts\",\"amounts\" ]], index = \"order_id\")\n",
    "print(\"以 order_id 作为分组键创建的订单透视表为：\\n\", detailPivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改聚合函数后的透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以 order_id 作为分组键创建的订单销量与售价总和透视表为：\n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002        224.0     7.0\n",
      "1003        241.0    10.0\n",
      "1004        702.0    17.0\n",
      "1008        315.0     5.0\n",
      "1011        577.0    10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot1 = pd.pivot_table(detail[[ \"order_id\",\"counts\",\"amounts\" ]], index = \"order_id\", aggfunc = np.sum)\n",
    "print(\"以 order_id 作为分组键创建的订单销量与售价总和透视表为：\\n\", detailPivot1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用订单号和菜品名称作为索引的透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以 order_id 和 dishes_name 作为分组键创建的订单销量与售价总和透视表为：\n",
      "                       amounts  counts\n",
      "order_id dishes_name                 \n",
      "1002     凉拌菠菜            27.0     1.0\n",
      "         南瓜枸杞小饼干         19.0     1.0\n",
      "         焖猪手             58.0     1.0\n",
      "         独家薄荷鲜虾牛肉卷       45.0     1.0\n",
      "         白胡椒胡萝卜羊肉汤       35.0     1.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot2 = pd.pivot_table(detail[[ \"order_id\",\"dishes_name\",\"counts\",\"amounts\" ]], index = [ \"order_id\",\"dishes_name\" ], aggfunc = np.sum)\n",
    "print(\"以 order_id 和 dishes_name 作为分组键创建的订单销量与售价总和透视表为：\\n\", detailPivot2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指定菜品名称为列分组键的透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以 order_id 和 dishes_name 作为行列分组键创建的透视表前5行4列为：\n",
      "             amounts                        \n",
      "dishes_name  42度海之蓝  北冰洋汽水  38度剑南春  50度古井贡酒\n",
      "order_id                                   \n",
      "1002            NaN     NaN     NaN     NaN\n",
      "1003            NaN     NaN     NaN     NaN\n",
      "1004            NaN     NaN     NaN     NaN\n",
      "1008            NaN     NaN     NaN     NaN\n",
      "1011           99.0     NaN     NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "detailPivot2 = pd.pivot_table(detail[[ \"order_id\",\"dishes_name\",\"counts\",\"amounts\" ]], index = \"order_id\", columns = \"dishes_name\", aggfunc = np.sum)\n",
    "print(\"以 order_id 和 dishes_name 作为行列分组键创建的透视表前5行4列为：\\n\", detailPivot2.iloc[:5,:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指定某些列制作透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以 order_id 作为行分组键 counts 作为值创建的透视表前5行为：\n",
      "           counts\n",
      "order_id        \n",
      "1002         7.0\n",
      "1003        10.0\n",
      "1004        17.0\n",
      "1008         5.0\n",
      "1011        10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot4 = pd.pivot_table(detail[[ \"order_id\",\"dishes_name\",\"counts\",\"amounts\" ]], index = \"order_id\", values = \"counts\", aggfunc = np.sum)\n",
    "print(\"以 order_id 作为行分组键 counts 作为值创建的透视表前5行为：\\n\", detailPivot4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对透视表中的缺失值进行填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空值填0后以 order_id 和 dishes_name 为行列分组键创建透视表前5行4列为：\n",
      "             amounts                        \n",
      "dishes_name  42度海之蓝  北冰洋汽水  38度剑南春  50度古井贡酒\n",
      "order_id                                   \n",
      "1002              0       0       0       0\n",
      "1003              0       0       0       0\n",
      "1004              0       0       0       0\n",
      "1008              0       0       0       0\n",
      "1011             99       0       0       0\n"
     ]
    }
   ],
   "source": [
    "detailPivot5 = pd.pivot_table(detail[[ \"order_id\",\"dishes_name\",\"counts\",\"amounts\" ]], index = \"order_id\", columns = \"dishes_name\", aggfunc = np.sum, fill_value = 0)\n",
    "print(\"空值填0后以 order_id 和 dishes_name 为行列分组键创建透视表前5行4列为：\\n\", detailPivot5.iloc[:5,:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在透视表中添加汇总数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "添加 margins 以后 order_id 和 dishes_name 为分组键的透视表前5行后4列为：\n",
      "             counts                    \n",
      "dishes_name 黄油曲奇饼干 黄花菜炒木耳 黑米恋上葡萄   All\n",
      "order_id                              \n",
      "1002             0      0      0   7.0\n",
      "1003             0      0      0  10.0\n",
      "1004             0      1      0  17.0\n",
      "1008             0      0      0   5.0\n",
      "1011             0      0      0  10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot6 = pd.pivot_table(detail[[ \"order_id\",\"dishes_name\",\"counts\",\"amounts\" ]], index = \"order_id\", columns = \"dishes_name\", aggfunc = np.sum, fill_value = 0, margins = True)\n",
    "print(\"添加 margins 以后 order_id 和 dishes_name 为分组键的透视表前5行后4列为：\\n\", detailPivot6.iloc[:5,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 crosstab 函数创建交叉表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crosstab 函数：\n",
    "\n",
    "pandas.crosstab(index, columns, values = None, rownames = None, colnames = None, aggfunc = None, margins = False, dropna = True, normalize = False)\n",
    "\n",
    "index                       接受 string 或 list。表示行索引值。无默认\n",
    "\n",
    "columns                     接受 string 或 list。表示列索引值。无默认\n",
    "\n",
    "values                      接受 array。表示聚合数据。默认为 None\n",
    "\n",
    "rownames                    表示行分组键名。无默认\n",
    "\n",
    "colnames                    表示列分组键名。无默认\n",
    "\n",
    "aggfunc                     接收 function。表示聚合函数。默认为 None\n",
    "\n",
    "margins                     接收 boolean。默认为 True。表示汇总（Total）功能的开关，设置为 True 后，结果集中会出现名为“ALL”的行和列\n",
    "\n",
    "dropna                      接受 boolean。表示是否删掉全为 NaN 的列。默认为 False\n",
    "\n",
    "normalize                   接受 boolean。表示是否对值进行标准化。默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 crosstab 函数制作交叉表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以 order_id 和 dishes_name 为分组键 counts 为值得透视表前5行5列为：\n",
      " dishes_name   42度海之蓝   北冰洋汽水   38度剑南春   50度古井贡酒  52度泸州老窖 \n",
      "order_id                                                 \n",
      "1002             NaN      NaN      NaN      NaN       NaN\n",
      "1003             NaN      NaN      NaN      NaN       NaN\n",
      "1004             NaN      NaN      NaN      NaN       NaN\n",
      "1008             NaN      NaN      NaN      NaN       NaN\n",
      "1011             1.0      NaN      NaN      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "detailCross = pd.crosstab(index = detail[\"order_id\"], columns = detail[\"dishes_name\"], values = detail[\"counts\"], aggfunc = np.sum)\n",
    "print(\"以 order_id 和 dishes_name 为分组键 counts 为值得透视表前5行5列为：\\n\", detailCross.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表单日菜品成交总额与总数透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表单日菜品成交总额与总数透视表前5行为：\n",
      "             amounts  counts\n",
      "date                       \n",
      "2016-08-01   9366.0   233.0\n",
      "2016-08-02   6125.0   151.0\n",
      "2016-08-03   6890.0   192.0\n",
      "2016-08-04   7549.0   169.0\n",
      "2016-08-05   8671.0   224.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = pd.read_sql_table(\"meal_order_detail1\", con = engine)\n",
    "detail[\"place_order_time\"] = pd.to_datetime(detail[\"place_order_time\"])\n",
    "detail[\"date\"] = [i.date() for i in detail[\"place_order_time\"]]\n",
    "PivotDetail = pd.pivot_table(detail[[ \"date\",\"dishes_name\",\"counts\",\"amounts\" ]], index = \"date\", aggfunc = np.sum, margins = True)\n",
    "print(\"订单详情表单日菜品成交总额与总数透视表前5行为：\\n\", PivotDetail.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表单个菜品单日成交总额透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表单个菜品单日成交总额交叉表后5行5列为：\n",
      " dishes_name  黄尾袋鼠西拉子红葡萄酒  黄油曲奇饼干  黄花菜炒木耳  黑米恋上葡萄       All\n",
      "date                                                      \n",
      "2016-08-07         230.0    32.0   105.0    99.0   31306.0\n",
      "2016-08-08          46.0     NaN     NaN    33.0    6532.0\n",
      "2016-08-09         138.0     NaN    35.0    99.0    7155.0\n",
      "2016-08-10          46.0     NaN    70.0    33.0   10231.0\n",
      "All                736.0    80.0   525.0   561.0  125992.0\n"
     ]
    }
   ],
   "source": [
    "CrossDetail = pd.crosstab(index = detail[\"date\"], columns = detail[\"dishes_name\"], values = detail[\"amounts\"], aggfunc = np.sum, margins = True)\n",
    "print(\"订单详情表单个菜品单日成交总额交叉表后5行5列为：\\n\",CrossDetail.iloc[-5:,-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 堆叠合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat 函数：\n",
    "\n",
    "pandas.concat(objs, axis = 0, join = \"outer\", join_axes = None, ignore_index = False, keys = None, levels = None, names = None, verify_integrity = False, copy = True)\n",
    "\n",
    "objs                 接收多个 Series、DataFrame、Panel 的组合。表示参与连接的 pandas 对象的列表的组合。无默认\n",
    "\n",
    "axis                 接收0或1。表示连接的轴向，默认为0\n",
    "\n",
    "join                 接收 inner 或 outer。表示其他轴向上的索引是按交集（inner）还是并集（outer）进行合并。默认为 outer\n",
    "\n",
    "join_axes            接收 Index 对象。表示用于其他 n-1 条轴的索引，不执行并集/交集运算\n",
    "\n",
    "ignore_index         接收 boolean。表示是否不保留连接轴上的索引，产生一组新索引 range(total_length)。默认为 False\n",
    "\n",
    "keys                 接收 sequence。表示与连接对象有关的值，用于形成连接轴向上的层次化索引。默认为 None\n",
    "\n",
    "levels               接收包含多个 sequence 的 list。表示在指定 keys 参数后，指定用作层次化索引各级别上的索引。默认为 None\n",
    "\n",
    "names                接收 list。表示在设置了 keys 和 levels 参数后，用于创建分层级别的名称。默认为 None\n",
    "\n",
    "verify_integrity     接收 boolean。检查新连接的轴是否包含重复项。如果发现重复项，则引发异常。默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 索引完全相同时的横向堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并 df1 的大小为(2779, 10)，df2 的大小为(2779, 9)。\n",
      "內连接合并后的数据框大小为： (2779, 19)\n",
      "外连接合并后的数据框大小为： (2779, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/testdb?charset=utf8\")\n",
    "detail1 = pd.read_sql(\"meal_order_detail1\", conn)\n",
    "df1 = detail1.iloc[:,:10] # 取出 detail 的前10列数据\n",
    "df2 = detail1.iloc[:,10:] # 取出 detail 的后9列数据\n",
    "print(\"合并 df1 的大小为%s，df2 的大小为%s。\"%(df1.shape, df2.shape))\n",
    "print(\"內连接合并后的数据框大小为：\",pd.concat([df1, df2], axis = 1, join = \"inner\").shape)\n",
    "print(\"外连接合并后的数据框大小为：\",pd.concat([df1, df2], axis = 1, join = \"outer\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表名完全相同时的 concat 纵向堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并 df3 的大小为(1500, 19)，df4 的大小为(1279, 19)\n",
      "外连接纵向合并后的数据框大小为： (2779, 38)\n",
      "內连接纵向合并后的数据框大小为： (0, 38)\n"
     ]
    }
   ],
   "source": [
    "df3 = detail1.iloc[:1500,:] # 取出 detail 前1500行数据\n",
    "df4 = detail1.iloc[1500:,:] # 取出 detail 的1500后的数据\n",
    "print(\"合并 df3 的大小为%s，df4 的大小为%s\"%(df3.shape, df4.shape))\n",
    "print(\"外连接纵向合并后的数据框大小为：\",pd.concat([df3, df4], axis = 1, join = \"outer\").shape)\n",
    "print(\"內连接纵向合并后的数据框大小为：\",pd.concat([df3, df4], axis = 1, join = \"inner\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# append 方法的基本语法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append 函数：\n",
    "\n",
    "pandas.DataFrame.append(self, other, ignore_index = False, verify_integrity = False)\n",
    "\n",
    "other                    接收 DataFrame 或 Series。表示要添加的新数据。无默认\n",
    "\n",
    "ignore_index             接收 boolean。如果输入 True，就会对新生成的 DataFrame 使用新的索引（自动产生），而忽略原来数据的索引。默认为 False\n",
    "\n",
    "verify_integrity         接收 boolean。如果输入 True，那么当 ignore_index 为 False 时，会检查添加的数据索引是否冲突，如果冲突，则会添加失败。                          默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 append 方法进行纵向表堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠前 df3 的大小为(1500, 19)，df4 的大小为(1279, 19)\n",
      "append 纵向堆叠后的数据框大小为： (2779, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"堆叠前 df3 的大小为%s，df4 的大小为%s\"%(df3.shape, df4.shape))\n",
    "print(\"append 纵向堆叠后的数据框大小为：\",df3.append(df4).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主键合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge 函数：\n",
    "\n",
    "pandas.merge(left, right, how = \"inner\", on = None, left_on = None, right_on = None, left_index = False, right_index = False, sort = False, suffixes = (\"_x\", \"_y\"), copy = True, indicator = False)\n",
    "\n",
    "left                 接收 DataFrame 或 Series。表示要添加的新数据1。无默认\n",
    "\n",
    "right                接收 DataFrame 或 Series。表示要添加的新数据2。无默认\n",
    "\n",
    "how                  接收 inner、outer、left、right。表示数据的连接方式。默认为 inner\n",
    "\n",
    "on                   接收 string 或 sequence。表示两个数据合并的主键（必须一致）。默认为 None\n",
    "\n",
    "left_on              接收 string 或 sequence。表示 left 参数接收数据用于合并的主键。默认为 None\n",
    "\n",
    "right_on             接收 string 或 sequence。表示 right 参数接收数据用于合并的主键。默认为 None\n",
    "\n",
    "left_index           接收 boolean。表示是否将 left 参数接收数据的 index 作为连接主键。默认为 False\n",
    "\n",
    "right_index          接受 boolean。表示是否将 right 参数接收数据的 index 作为连接主键。默认为 False\n",
    "\n",
    "sort                 接收 boolean。表示是否根据连接键对合并后的数据进行排序。默认为 False\n",
    "\n",
    "suffixes             接受 tuple。表示用于追加到 left 和 right 参数接收数据列名相同时的后缀。默认为 (\"_x\", \"_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 merge 函数合并数据表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail1订单详情表的原始形状为： (2779, 19)\n",
      "order订单信息表的原始形状为： (945, 21)\n",
      "订单详情表和订单信息表主键合并后的形状为： (2779, 40)\n"
     ]
    }
   ],
   "source": [
    "order = pd.read_csv(\"../data/meal_order_info.csv\", sep = \",\", encoding = \"gb18030\") # 读取订单信息表\n",
    "\n",
    "# 将 info_id 转换为字符串格式，为合并做准备\n",
    "\n",
    "order[\"info_id\"] = order[\"info_id\"].astype(\"str\")\n",
    "\n",
    "# 订单详情表和订单信息表都有订单编号\n",
    "# 在订单详情表中为 order_id，在订单信息表中为 info_id\n",
    "\n",
    "order_detail = pd.merge(detail1, order, left_on = \"order_id\", right_on = \"info_id\")\n",
    "print(\"detail1订单详情表的原始形状为：\", detail1.shape)\n",
    "print(\"order订单信息表的原始形状为：\", order.shape)\n",
    "print(\"订单详情表和订单信息表主键合并后的形状为：\", order_detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join 方法实现部分主键合并的功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join 函数：\n",
    "\n",
    "pandas.DataFrame.join(self, other, on = None, how = \"left\", lsuffix = \"\", rsuffix = \"\", sort = False)\n",
    "\n",
    "other          接收 DataFrame、Series 或者包含了多个 DataFrame 的 list。表示参与连接的其他 DataFrame。无默认\n",
    "\n",
    "on             接收特定 string。inner 代表内连接；outer 代表外连接；left 和 right 分别代表左连接和右连接。默认为 inner\n",
    "\n",
    "lsuffix        接收 string。表示用于追加到左侧重叠列名的尾缀。无默认\n",
    "\n",
    "rsuffix        接收 string。表示用于追加到右侧重叠列名的尾缀。无默认\n",
    "\n",
    "sort           接收 boolean。根据连接键对合并后的数据进行排序，默认为 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 join 方法实现主键合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-1977d373e78f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m\"info_id\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"order_id\"\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0morder_detail1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetail1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"order_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"订单详情表和订单信息表 join 合并后的形状为：\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_detail1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   6324\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6325\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 6326\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   6327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6328\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   6339\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[0;32m   6340\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6341\u001b[1;33m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[0;32m   6342\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6343\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# to avoid incompat dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# If argument passed to validate,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "order.rename({ \"info_id\":\"order_id\" }, inplace = True)\n",
    "order_detail1 = detail1.join(order, on = \"order_id\", rsuffix = \"1\")\n",
    "print(\"订单详情表和订单信息表 join 合并后的形状为：\", order_detail1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine_first 方法的具体用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine_first 函数：\n",
    "\n",
    "pandas.DataFrame.combine_first(other)\n",
    "\n",
    "other          接收 DataFrame。表示参与重叠合并的另一个 DataFrame。无默认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过重叠合并后的数据为：\n",
      "    ID System cpu\n",
      "0   1  win10  i7\n",
      "1   2  win10  i5\n",
      "2   3   win7  i3\n",
      "3   4  win10  i7\n",
      "4   5   win8  i7\n",
      "5   6   win7  i5\n",
      "6   7   win7  i5\n",
      "7   8   win7  i5\n",
      "8   9   win8  i3\n"
     ]
    }
   ],
   "source": [
    "# 建立两个字典，除了 ID 外，别的特征互补\n",
    "\n",
    "dict1 = { \"ID\":[ 1,2,3,4,5,6,7,8,9 ], \"System\":[ \"win10\",\"win10\",np.nan,\"win10\",np.nan,np.nan,\"win7\",\"win7\",\"win8\" ],\n",
    "        \"cpu\":[ \"i7\",\"i5\",np.nan,\"i7\",np.nan,np.nan,\"i5\",\"i5\",\"i3\" ] }\n",
    "dict2 = { \"ID\":[ 1,2,3,4,5,6,7,8,9 ], \"System\":[ np.nan,np.nan,\"win7\",np.nan,\"win8\",\"win7\",np.nan,np.nan,np.nan ],\n",
    "        \"cpu\":[ np.nan,np.nan,\"i3\",np.nan,\"i7\",\"i5\",np.nan,np.nan,np.nan ]}\n",
    "\n",
    "# 转换两个字典为 DataFrame\n",
    "\n",
    "df5 = pd.DataFrame(dict1)\n",
    "df6 = pd.DataFrame(dict2)\n",
    "print(\"经过重叠合并后的数据为：\\n\", df5.combine_first(df6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将多张菜品订单详情表纵向合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3张订单详情表合并后的形状为： (10037, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 创建数据库连接\n",
    "\n",
    "conn = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/testdb?charset=utf8\")\n",
    "\n",
    "# 读取数据\n",
    "\n",
    "detail1 = pd.read_sql(\"meal_order_detail1\", conn)\n",
    "detail2 = pd.read_sql(\"meal_order_detail2\", conn)\n",
    "detail3 = pd.read_sql(\"meal_order_detail3\", conn)\n",
    "\n",
    "#纵向堆叠3张表\n",
    "\n",
    "detail = detail1.append(detail2)\n",
    "detail = detail.append(detail3)\n",
    "print(\"3张订单详情表合并后的形状为：\", detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单详情表、订单信息表、客户信息表主键合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3张表数据主键合并后的大小为： (10037, 56)\n"
     ]
    }
   ],
   "source": [
    "order = pd.read_csv(\"../data/meal_order_info.csv\", sep = \",\", encoding = \"gb18030\") # 读取订单信息表\n",
    "user = pd.read_excel(\"../data/users_info.xlsx\") # 读取客户信息表\n",
    "\n",
    "# 数据类型转换，存储部分数据\n",
    "\n",
    "order[\"info_id\"] = order[\"info_id\"].astype(\"str\")\n",
    "order[\"emp_id\"] = order[\"emp_id\"].astype(\"str\")\n",
    "user[\"USER_ID\"] = user[\"USER_ID\"].astype(\"str\")\n",
    "data = pd.merge(detail, order, left_on = [ \"order_id\",\"emp_id\" ], right_on = [ \"info_id\",\"emp_id\" ])\n",
    "data = pd.merge(detail, user, left_on = \"emp_id\", right_on = \"USER_ID\", how = \"inner\")\n",
    "print(\"3张表数据主键合并后的大小为：\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
